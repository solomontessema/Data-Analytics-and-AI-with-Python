{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ItgQO2PRkJ_SxtozH2oUyIOBWKqvMt6L",
      "authorship_tag": "ABX9TyNoMB5qK9rbuu/e4AAfs/lk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solomontessema/Data-Analytics-and-AI-with-Python/blob/main/notebooks/PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "DUQ4g5Un_TTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Java\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Download Spark from a stable mirror\n",
        "!wget -q https://mirrors.huaweicloud.com/apache/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "\n",
        "# Extract Spark\n",
        "!tar -xvf spark-3.4.1-bin-hadoop3.tgz\n",
        "\n",
        "# Install findspark\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "QbBlQxSn_t-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"AirbnbReviews\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "JENEQEjnBHgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"/content/drive/MyDrive/listings.csv\", header=True, inferSchema=True)\n",
        "df.printSchema()\n",
        "df.show(5)\n"
      ],
      "metadata": {
        "id": "4FAxJAZqD01d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, to_date\n",
        "\n",
        "df_clean = df.filter(col(\"price\").isNotNull())\n",
        "df_clean = df_clean.withColumn(\"last_review\", to_date(col(\"last_review\")))\n",
        "df_clean.select(\"id\", \"name\", \"price\", \"last_review\").show()\n"
      ],
      "metadata": {
        "id": "5-XmuzfCEW7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.groupBy(\"room_type\").avg(\"price\").orderBy(\"avg(price)\", ascending=False).show()\n"
      ],
      "metadata": {
        "id": "Ocda9euwEt62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.groupBy(\"neighbourhood\").count().orderBy(\"count\", ascending=False).show()"
      ],
      "metadata": {
        "id": "imE_3eLyE9Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.write.parquet(\"/content/drive/MyDrive/listings_clean.parquet\")\n",
        "\n"
      ],
      "metadata": {
        "id": "AiVYpr1nHEke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.groupby(\"name\").avg(\"reviews_per_month\").orderBy(\"name\",ascending =True).show()"
      ],
      "metadata": {
        "id": "LC6WAyfnJokH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.groupBy(\"name\").count().show()"
      ],
      "metadata": {
        "id": "elyBHbfUKm7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.join(df_clean,df_clean[\"name\"]==df_clean[\"name\"], \"inner\").show()\n"
      ],
      "metadata": {
        "id": "YPA2NlN0LVUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, isnan\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "df = spark.read.csv(\"/content/drive/MyDrive/listings.csv\", header=True, inferSchema=True)\n",
        "\n",
        "df_clean = df.dropna(subset=[\"room_type\", \"minimum_nights\", \"number_of_reviews\", \"price\"])\n",
        "df_clean = df_clean.withColumn(\"number_of_reviews\", col(\"number_of_reviews\").cast(\"double\"))\n",
        "df_clean = df_clean.withColumn(\"minimum_nights\", col(\"minimum_nights\").cast(\"double\"))\n",
        "df_clean = df_clean.withColumn(\"price\", col(\"price\").cast(\"double\"))\n",
        "df_clean = df_clean.filter((~isnan(\"price\")) & (col(\"price\").isNotNull()))\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"room_type\", outputCol=\"room_type_index\")\n",
        "df_indexed = indexer.fit(df_clean).transform(df_clean)\n",
        "\n",
        "df_indexed = df_indexed.filter(\n",
        "    (col(\"minimum_nights\").isNotNull()) &\n",
        "    (col(\"number_of_reviews\").isNotNull()) &\n",
        "    (col(\"room_type_index\").isNotNull()) &\n",
        "    (col(\"price\").isNotNull())\n",
        ")\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"room_type_index\", \"minimum_nights\", \"number_of_reviews\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "df_vector = assembler.transform(df_indexed)\n",
        "df_vector = df_vector.filter(col(\"features\").isNotNull())\n",
        "\n",
        "\n",
        "train_df, test_df = df_vector.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"price\")\n",
        "model = lr.fit(train_df)\n",
        "\n",
        "predictions = model.transform(test_df)\n",
        "\n",
        "evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"RMSE: {rmse}\")\n"
      ],
      "metadata": {
        "id": "uF5_7VIXsQX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/linear_model\")"
      ],
      "metadata": {
        "id": "_kC_iIqpuQAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegressionModel\n",
        "loaded_model = LinearRegressionModel.load(\"/content/drive/MyDrive/linear_model\")\n"
      ],
      "metadata": {
        "id": "ybJsfKd1umTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.ml.regression import LinearRegressionModel\n",
        "\n",
        "sample_data = [Row(features=Vectors.dense([1.0, 3.0, 25.0]))]\n",
        "sample_df = spark.createDataFrame(sample_data)\n",
        "\n",
        "prediction = loaded_model.transform(sample_df)\n",
        "prediction.select(\"features\", \"prediction\").show()"
      ],
      "metadata": {
        "id": "K2Cl6wYHurQI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}